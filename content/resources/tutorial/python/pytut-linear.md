---
title: Python Tutorial - Linear Regression in Python
linktitle: RegresiÃ³n lineal en Python
toc: true
type: docs
date: "2019-09-15T00:00:00+01:00"
draft: false
menu:
  python:
    parent: Machine Learning en Python
    weight: 1

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 1
---

Vivimos en la era de grandes cantidades de datos, computadoras potentes e inteligencia artificial. Este es solo el comienzo. La ciencia de datos y el aprendizaje automÃ¡tico estÃ¡n impulsando el reconocimiento de imÃ¡genes, el desarrollo de vehÃ­culos autÃ³nomos, las decisiones en los sectores financiero y energÃ©tico, los avances en medicina, el auge de las redes sociales y mÃ¡s. La regresiÃ³n lineal es una parte importante de esto.

La regresiÃ³n lineal es una de las tÃ©cnicas estadÃ­sticas y de aprendizaje automÃ¡tico fundamentales. Ya sea que desee hacer estadÃ­sticas, aprendizaje automÃ¡tico o computaciÃ³n cientÃ­fica, hay buenas posibilidades de que lo necesite. Es recomendable aprenderlo primero y luego proceder hacia mÃ©todos mÃ¡s complejos.

Al final de este artÃ­culo, habrÃ¡s aprendido:

Â¿QuÃ© es la regresiÃ³n lineal?
Para quÃ© regresiÃ³n lineal se utiliza
CÃ³mo funciona la regresiÃ³n lineal
CÃ³mo implementar la regresiÃ³n lineal en Python, paso a paso


RegresiÃ³n
El anÃ¡lisis de regresiÃ³n es uno de los campos mÃ¡s importantes en estadÃ­stica y aprendizaje automÃ¡tico. Hay muchos mÃ©todos de regresiÃ³n disponibles. La regresiÃ³n lineal es una de ellas.

Â¿QuÃ© es la regresiÃ³n?
La regresiÃ³n busca relaciones entre variables.

Por ejemplo, puede observar a varios empleados de alguna compaÃ±Ã­a e intentar comprender cÃ³mo sus salarios dependen de las caracterÃ­sticas, como la experiencia, el nivel de educaciÃ³n, el rol, la ciudad en la que trabajan, etc.

Este es un problema de regresiÃ³n en el que los datos relacionados con cada empleado representan una observaciÃ³n. La presunciÃ³n es que la experiencia, la educaciÃ³n, el rol y la ciudad son las caracterÃ­sticas independientes, mientras que el salario depende de ellas.

Del mismo modo, puede intentar establecer una dependencia matemÃ¡tica de los precios de las casas en sus Ã¡reas, nÃºmero de dormitorios, distancias al centro de la ciudad, etc.

En general, en el anÃ¡lisis de regresiÃ³n, generalmente considera algÃºn fenÃ³meno de interÃ©s y tiene una serie de observaciones. Cada observaciÃ³n tiene dos o mÃ¡s caracterÃ­sticas. Siguiendo el supuesto de que (al menos) una de las caracterÃ­sticas depende de las otras, intenta establecer una relaciÃ³n entre ellas.

En otras palabras, debe encontrar una funciÃ³n que asigne algunas caracterÃ­sticas o variables a otras lo suficientemente bien.

Las caracterÃ­sticas dependientes se denominan variables dependientes, salidas o respuestas.

Las caracterÃ­sticas independientes se denominan variables independientes, entradas o predictores.

Los problemas de regresiÃ³n generalmente tienen una variable dependiente continua y sin lÃ­mites. Sin embargo, las entradas pueden ser datos continuos, discretos o incluso categÃ³ricos, como gÃ©nero, nacionalidad, marca, etc.

Es una prÃ¡ctica comÃºn denotar las salidas con ğ‘¦ y las entradas con ğ‘¥. Si hay dos o mÃ¡s variables independientes, se pueden representar como el vector ğ± = (ğ‘¥â‚, ..., ğ‘¥áµ£), donde ğ‘Ÿ es el nÃºmero de entradas.


Â¿CuÃ¡ndo necesitas regresiÃ³n?
Por lo general, se necesita una regresiÃ³n para responder si un fenÃ³meno influye en el otro y cÃ³mo se relacionan varias variables. Por ejemplo, puede usarlo para determinar si y en quÃ© medida la experiencia o el gÃ©nero afectan los salarios.

La regresiÃ³n tambiÃ©n es Ãºtil cuando desea pronosticar una respuesta utilizando un nuevo conjunto de predictores. Por ejemplo, podrÃ­a intentar predecir el consumo de electricidad de un hogar para la prÃ³xima hora dada la temperatura exterior, la hora del dÃ­a y el nÃºmero de residentes en ese hogar.

La regresiÃ³n se usa en muchos campos diferentes: economÃ­a, ciencias de la computaciÃ³n, ciencias sociales, etc. Su importancia aumenta cada dÃ­a con la disponibilidad de grandes cantidades de datos y una mayor conciencia del valor prÃ¡ctico de los datos.

RegresiÃ³n lineal
La regresiÃ³n lineal es probablemente una de las tÃ©cnicas de regresiÃ³n mÃ¡s importantes y ampliamente utilizadas. Es uno de los mÃ©todos de regresiÃ³n mÃ¡s simples. Una de sus principales ventajas es la facilidad de interpretaciÃ³n de los resultados.

FormulaciÃ³n del problema
Al implementar la regresiÃ³n lineal de alguna variable dependiente ğ‘¦ en el conjunto de variables independientes ğ± = (ğ‘¥â‚, ..., ğ‘¥áµ£), donde ğ‘Ÿ es el nÃºmero de predictores, se supone una relaciÃ³n lineal entre ğ‘¦ y ğ±: ğ‘¦ = ğ›½â‚€ + ğ›½â‚ğ‘¥â‚ + â‹¯ + ğ›½áµ£ğ‘¥áµ£ + ğœ€. Esta ecuaciÃ³n es la ecuaciÃ³n de regresiÃ³n. ğ›½â‚€, ğ›½â‚, ..., ğ›½áµ£ son los coeficientes de regresiÃ³n, y ğœ€ es el error aleatorio.

La regresiÃ³n lineal calcula los estimadores de los coeficientes de regresiÃ³n o simplemente los pesos predichos, denotados con ğ‘â‚€, ğ‘â‚, ..., ğ‘áµ£. Definen la funciÃ³n de regresiÃ³n estimada ğ‘“ (ğ±) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + â‹¯ + ğ‘áµ£ğ‘¥áµ£. Esta funciÃ³n debe capturar las dependencias entre las entradas y salidas lo suficientemente bien.

La respuesta estimada o pronosticada, ğ‘“ (ğ±áµ¢), para cada observaciÃ³n ğ‘– = 1, ..., ğ‘›, debe estar lo mÃ¡s cerca posible de la respuesta real correspondiente ğ‘¦áµ¢. Las diferencias ğ‘¦áµ¢ - ğ‘“ (ğ±áµ¢) para todas las observaciones ğ‘– = 1, ..., ğ‘›, se denominan residuales. La regresiÃ³n se trata de determinar los mejores pesos pronosticados, es decir, los pesos correspondientes a los residuos mÃ¡s pequeÃ±os.

Para obtener los mejores pesos, generalmente minimiza la suma de los residuos cuadrados (SSR) para todas las observaciones ğ‘– = 1, ..., ğ‘›: SSR = Î£áµ¢ (ğ‘¦áµ¢ - ğ‘“ (ğ±áµ¢)) Â². Este enfoque se llama el mÃ©todo de mÃ­nimos cuadrados ordinarios.


Rendimiento de regresiÃ³n
La variaciÃ³n de las respuestas reales ğ‘¦áµ¢, ğ‘– = 1, ..., ğ‘›, se debe en parte a la dependencia de los predictores ğ±áµ¢. Sin embargo, tambiÃ©n hay una variaciÃ³n inherente adicional de la salida.

El coeficiente de determinaciÃ³n, denotado como ğ‘…Â², le indica quÃ© cantidad de variaciÃ³n en ğ‘¦ puede explicarse por la dependencia de ğ± utilizando el modelo de regresiÃ³n particular. Mayor ğ‘…Â² indica un mejor ajuste y significa que el modelo puede explicar mejor la variaciÃ³n de la salida con diferentes entradas.

El valor ğ‘…Â² = 1 corresponde a SSR = 0, es decir, al ajuste perfecto ya que los valores de las respuestas pronosticadas y reales se ajustan completamente entre sÃ­.

RegresiÃ³n lineal simple
La regresiÃ³n lineal simple o de una sola variable es el caso mÃ¡s simple de regresiÃ³n lineal con una sola variable independiente, ğ± = ğ‘¥.

La siguiente figura ilustra la regresiÃ³n lineal simple:


![][1]


[1]: ../fig-lin-reg.png
